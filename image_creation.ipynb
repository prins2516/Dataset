{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a09779-38b7-4982-bf52-a9e41a82515c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create directories\n",
    "USER_SRC_DIR = \"src_dir_sdk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5286fa-ccc3-434c-8e82-e11174447d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src_dir_sdk/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $USER_SRC_DIR/requirements.txt\n",
    "xgboost==1.6.2\n",
    "google-cloud-aiplatform==1.25.0\n",
    "fastapi\n",
    "numpy\n",
    "uvicorn==0.17.6\n",
    "pandas==1.3.5\n",
    "joblib==1.1.0\n",
    "scikit-learn==1.0.2\n",
    "google-cloud-storage>=1.26.0,<2.0.0\n",
    "shapely==1.8.5.post1 \n",
    "pygeos==0.12.0 \n",
    "geopandas==0.10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a290cd-cad1-4490-90dc-47b47b6cbf21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.prediction import LocalModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d5d821-4aed-47ea-8cf2-ade276131717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘src_dir_sdk’: File exists\n",
      "mkdir: cannot create directory ‘model_artifacts’: File exists\n",
      "Copying file://model_artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][184.5 KiB/184.5 KiB]                                                \n",
      "Operation completed over 1 objects/184.5 KiB.                                    \n",
      "gs://xgboost_new_-henry-scien-unique/xgboost-model-sdk/model.joblib\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up Google Cloud project and bucket\n",
    "PROJECT_ID = \"henry-scien\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "MODEL_ARTIFACT_DIR = \"xgboost-model-sdk\"\n",
    "REPOSITORY = \"custom-container-prediction-sdk\"\n",
    "IMAGE = \"xgboost-server-sdk\"\n",
    "MODEL_DISPLAY_NAME = \"xgboost-model-sdk\"\n",
    "BUCKET_NAME = \"xgboost_new_-henry-scien-unique\"\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "\n",
    "\n",
    "LOCAL_MODEL_ARTIFACTS_DIR = \"model_artifacts\"\n",
    "%mkdir $USER_SRC_DIR\n",
    "%mkdir $LOCAL_MODEL_ARTIFACTS_DIR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train and export the model\n",
    "url = \"https://raw.githubusercontent.com/prins2516/Dataset/main/datasets_228_482_diabetes.csv\"\n",
    "raw_data = pd.read_csv(url)\n",
    "X = raw_data.drop(['Outcome'], axis=1)\n",
    "y = raw_data['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "xgbc = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, gamma=0, subsample=0.5, colsample_bytree=1, max_depth=8)\n",
    "xgbc.fit(X_train, y_train)\n",
    "\n",
    "predictions = xgbc.predict(X_test)\n",
    "score = accuracy_score(y_test, predictions)\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "precision_recall_curve(y_test, predictions)\n",
    "\n",
    "os.makedirs(\"model_artifacts\", exist_ok=True)\n",
    "joblib.dump(xgbc, \"model_artifacts/model.joblib\")\n",
    "\n",
    "# Upload model artifacts to GCS\n",
    "!gsutil cp model_artifacts/* $BUCKET_URI/$MODEL_ARTIFACT_DIR/\n",
    "!gsutil ls $BUCKET_URI/$MODEL_ARTIFACT_DIR/\n",
    "\n",
    "# Build the custom container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b29b301-8cb4-4196-b640-06c6d2cac058",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src_dir_sdk/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src_dir_sdk/predictor.py\n",
    "import joblib\n",
    "import numpy as np\n",
    " \n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "from google.cloud.aiplatform.prediction.predictor import Predictor\n",
    "class SklearnPredictor(Predictor):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    def load(self, artifacts_uri: str):\n",
    "        prediction_utils.download_model_artifacts(artifacts_uri)\n",
    "        self._model = joblib.load(\"model.joblib\")\n",
    " \n",
    "    def preprocess(self, prediction_input: dict) -> np.ndarray:\n",
    "        instances = prediction_input[\"instances\"]\n",
    "        return np.asarray(instances)\n",
    " \n",
    "    def predict(self, instances: np.ndarray) -> np.ndarray:\n",
    "        return self._model.predict(instances)\n",
    " \n",
    "    def postprocess(self, prediction_results: np.ndarray) -> dict:\n",
    "        return {\"predictions\": prediction_results.tolist()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b29a29b-a8db-4d97-bab3-ca33165ab885",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/opt/conda/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "from src_dir_sdk.predictor import SklearnPredictor\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "local_model = LocalModel.build_cpr_model(\n",
    "    USER_SRC_DIR,\n",
    "    f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\",\n",
    "    predictor=SklearnPredictor,\n",
    "    requirements_path=os.path.join(USER_SRC_DIR, \"requirements.txt\"),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e820e048-1879-459d-81b0-e9016f15199f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sample = {\"instances\": [[6, 140, 72, 35, 0, 33.6, 0.62, 48]]}\n",
    "\n",
    "with open('instances.json', 'w') as fp:\n",
    "    json.dump(sample, fp)\n",
    "    \n",
    "with local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri = 'model_artifacts/', # local path to artifacts\n",
    ") as local_endpoint:\n",
    "    predict_response = local_endpoint.predict(\n",
    "        request_file='instances.json',\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "\n",
    "    health_check_response = local_endpoint.run_health_check()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5aecceb-6037-4ca3-ad4d-4c05da46a243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"predictions\": [1]}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddfcbd65-94d2-40fe-8616-aac401d50649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create request issued for: [custom-container-prediction-sdk]\n",
      "Waiting for operation [projects/henry-scien/locations/us-central1/operations/a7\n",
      "04b8ee-9f1f-49e3-a262-a08b113c3a1e] to complete...done.                        \n",
      "Created repository [custom-container-prediction-sdk].\n",
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "Docker configuration file updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/opt/conda/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Push the image to Artifact Registry\n",
    "!gcloud artifacts repositories create {REPOSITORY} --repository-format=docker \\\n",
    "--location={REGION} --description=\"Docker repository\"\n",
    "!gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet\n",
    "local_model.push_image()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74256fd8-ccab-461a-b02c-4fd81932175f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-central1-docker.pkg.dev/henry-scien/custom-container-prediction-sdk/xgboost-server-sdk'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the model to Vertex AI Model Registry\n",
    "model = aiplatform.Model.upload(local_model=local_model,\n",
    "                                display_name=MODEL_DISPLAY_NAME,\n",
    "                                artifact_uri=f\"{BUCKET_URI}/{MODEL_ARTIFACT_DIR}\")\n",
    "\n",
    "# Deploy the model for online predictions\n",
    "endpoint = model.deploy(machine_type=\"n1-standard-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158a9e40-cbb3-4116-8e17-69f5db6a42ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BUCKET_URI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mBUCKET_URI\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_ARTIFACT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BUCKET_URI' is not defined"
     ]
    }
   ],
   "source": [
    "f\"{BUCKET_URI}/{MODEL_ARTIFACT_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac9102-921a-48cf-bb4e-478ef1bf8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "us-central1-docker.pkg.dev/henry-scien/custom-container-prediction-sdk/xgboost-server-sdk"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
